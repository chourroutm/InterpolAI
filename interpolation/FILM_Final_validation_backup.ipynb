{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-02T15:42:40.700156800Z",
     "start_time": "2025-04-02T15:42:38.396814200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydot.py:17: UserWarning: `pydot` could not import `dot_parser`, so `pydot` will be unable to parse DOT files. The error was:  No module named 'pyparsing'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from interpolation_function_skip import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T15:42:43.870049100Z",
     "start_time": "2025-04-02T15:42:43.856034200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# model = hub.load(\"https://tfhub.dev/google/film/1\")\n",
    "model_path = r\"C:\\Users\\saura\\PycharmProjects\\InterpolAI-3D\\model\"\n",
    "model = tf.saved_model.load(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T15:42:50.996637800Z",
     "start_time": "2025-04-02T15:42:45.849342200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "skips = [1]\n",
    "TILE_SIZE = (3000, 3000)\n",
    "# TILE_SIZE = (512, 512)\n",
    "pth=r\"\\\\10.99.68.178\\Saurabh\\manuscript_figs\\data\\HE_roi1\\authentic\\test\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T15:47:02.497706300Z",
     "start_time": "2025-04-02T15:47:02.482692300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating int 1 with skip 1:\n",
      "not stitching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpolating TC_001_0001.tif to TC_001_0006.tif: 100%|██████████| 1/1 [00:19<00:00, 19.13s/frame]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to generate TC_001_0001_to_TC_001_0006_int1.tif: 19.13 seconds\n",
      "loading image 1 from image 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not stitching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpolating TC_001_0003.tif to TC_001_0007.tif:   0%|          | 0/1 [00:11<?, ?frame/s]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'interpolate_bilinear/gather-bottom_left/GatherV2' defined at (most recent call last):\nNode: 'interpolate_bilinear/gather-bottom_left/GatherV2'\nOOM when allocating tensor with shape[1,1350000,195] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node interpolate_bilinear/gather-bottom_left/GatherV2}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_restored_function_body_13276]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# INTERPOLATES IMAGES SKIPPING AUTHENTIC IMAGES TO LATER COMPARE USING HARALICK METRICS\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43minterpolate_from_image_stack_combined\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskips\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mTILE_SIZE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\InterpolAI\\interpolation\\interpolation_function_skip.py:98\u001B[0m, in \u001B[0;36minterpolate_from_image_stack_combined\u001B[1;34m(pthims, skip_values, TILE_SIZE, model)\u001B[0m\n\u001B[0;32m     92\u001B[0m time1 \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([time_value], dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m     93\u001B[0m input_data \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39marray([time1], dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat32),\n\u001B[0;32m     95\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx0\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39mexpand_dims(image1, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m),\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx1\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39mexpand_dims(image2, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     97\u001B[0m }\n\u001B[1;32m---> 98\u001B[0m mid_frame \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     99\u001B[0m generated_image \u001B[38;5;241m=\u001B[39m mid_frame[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m    100\u001B[0m image_in_uint8_range \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mclip(generated_image \u001B[38;5;241m*\u001B[39m _UINT8_MAX_F, \u001B[38;5;241m0.0\u001B[39m, _UINT8_MAX_F)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:704\u001B[0m, in \u001B[0;36m_call_attribute\u001B[1;34m(instance, *args, **kwargs)\u001B[0m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_call_attribute\u001B[39m(instance, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 704\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m instance\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mResourceExhaustedError\u001B[0m: Graph execution error:\n\nDetected at node 'interpolate_bilinear/gather-bottom_left/GatherV2' defined at (most recent call last):\nNode: 'interpolate_bilinear/gather-bottom_left/GatherV2'\nOOM when allocating tensor with shape[1,1350000,195] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node interpolate_bilinear/gather-bottom_left/GatherV2}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_restored_function_body_13276]"
     ]
    }
   ],
   "source": [
    "# INTERPOLATES IMAGES SKIPPING AUTHENTIC IMAGES TO LATER COMPARE USING HARALICK METRICS\n",
    "interpolate_from_image_stack_combined(pth, skips, TILE_SIZE, model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T15:47:36.039755Z",
     "start_time": "2025-04-02T15:47:02.986606800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GOES THROUGH ALL INTERPOLATED FOLDERS AND RUNS ALL METRICS\n",
    "process_interpolated_images_for_haralick_features(pth, skips)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
