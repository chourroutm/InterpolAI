{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-10-16T11:46:37.337205Z",
     "end_time": "2024-10-16T11:46:48.461812Z"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: C:\\Users\\saura\\AppData\\Local\\Temp\\tfhub_modules\\2bc8869ae42f586158bb5df0a65ce2103bcc940c\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnatsort\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m natsorted\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mimageio\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mhub\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhttps://tfhub.dev/google/film/1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\wirtz_FILM\\lib\\site-packages\\tensorflow_hub\\module_v2.py:102\u001B[0m, in \u001B[0;36mload\u001B[1;34m(handle, tags)\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tags \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m is_hub_module_v1:\n\u001B[0;32m    101\u001B[0m     tags \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 102\u001B[0m obj \u001B[38;5;241m=\u001B[39m \u001B[43mtf_v1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msaved_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_v2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    103\u001B[0m obj\u001B[38;5;241m.\u001B[39m_is_hub_module_v1 \u001B[38;5;241m=\u001B[39m is_hub_module_v1  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\saved_model\\load.py:869\u001B[0m, in \u001B[0;36mload\u001B[1;34m(export_dir, tags, options)\u001B[0m\n\u001B[0;32m    778\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaved_model.load\u001B[39m\u001B[38;5;124m\"\u001B[39m, v1\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaved_model.load_v2\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    779\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(export_dir, tags\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    780\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Load a SavedModel from `export_dir`.\u001B[39;00m\n\u001B[0;32m    781\u001B[0m \n\u001B[0;32m    782\u001B[0m \u001B[38;5;124;03m  Signatures associated with the SavedModel are available as functions:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    867\u001B[0m \u001B[38;5;124;03m    ValueError: If `tags` don't match a MetaGraph in the SavedModel.\u001B[39;00m\n\u001B[0;32m    868\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m--> 869\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexport_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mroot\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\saved_model\\load.py:881\u001B[0m, in \u001B[0;36mload_internal\u001B[1;34m(export_dir, tags, options, loader_cls, filters)\u001B[0m\n\u001B[0;32m    876\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tags \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(tags, \u001B[38;5;28mset\u001B[39m):\n\u001B[0;32m    877\u001B[0m   \u001B[38;5;66;03m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001B[39;00m\n\u001B[0;32m    878\u001B[0m   \u001B[38;5;66;03m# sequences for nest.flatten, so we put those through as-is.\u001B[39;00m\n\u001B[0;32m    879\u001B[0m   tags \u001B[38;5;241m=\u001B[39m nest\u001B[38;5;241m.\u001B[39mflatten(tags)\n\u001B[0;32m    880\u001B[0m saved_model_proto, debug_info \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 881\u001B[0m     \u001B[43mloader_impl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_saved_model_with_debug_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexport_dir\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    883\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mlen\u001B[39m(saved_model_proto\u001B[38;5;241m.\u001B[39mmeta_graphs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m    884\u001B[0m     saved_model_proto\u001B[38;5;241m.\u001B[39mmeta_graphs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mHasField(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobject_graph_def\u001B[39m\u001B[38;5;124m\"\u001B[39m)):\n\u001B[0;32m    885\u001B[0m   meta_graph_def \u001B[38;5;241m=\u001B[39m saved_model_proto\u001B[38;5;241m.\u001B[39mmeta_graphs[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:56\u001B[0m, in \u001B[0;36mparse_saved_model_with_debug_info\u001B[1;34m(export_dir)\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse_saved_model_with_debug_info\u001B[39m(export_dir):\n\u001B[0;32m     44\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Reads the savedmodel as well as the graph debug info.\u001B[39;00m\n\u001B[0;32m     45\u001B[0m \n\u001B[0;32m     46\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;124;03m    parsed. Missing graph debug info file is fine.\u001B[39;00m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m---> 56\u001B[0m   saved_model \u001B[38;5;241m=\u001B[39m \u001B[43m_parse_saved_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexport_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     58\u001B[0m   debug_info_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[0;32m     59\u001B[0m       saved_model_utils\u001B[38;5;241m.\u001B[39mget_debug_dir(export_dir),\n\u001B[0;32m     60\u001B[0m       constants\u001B[38;5;241m.\u001B[39mDEBUG_INFO_FILENAME_PB)\n\u001B[0;32m     61\u001B[0m   debug_info \u001B[38;5;241m=\u001B[39m graph_debug_info_pb2\u001B[38;5;241m.\u001B[39mGraphDebugInfo()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:113\u001B[0m, in \u001B[0;36mparse_saved_model\u001B[1;34m(export_dir)\u001B[0m\n\u001B[0;32m    111\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot parse file \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (path_to_pbtxt, \u001B[38;5;28mstr\u001B[39m(e)))\n\u001B[0;32m    112\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 113\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\n\u001B[0;32m    114\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSavedModel file does not exist at: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m{\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m|\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m}\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m    115\u001B[0m       (export_dir, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39msep, constants\u001B[38;5;241m.\u001B[39mSAVED_MODEL_FILENAME_PBTXT,\n\u001B[0;32m    116\u001B[0m        constants\u001B[38;5;241m.\u001B[39mSAVED_MODEL_FILENAME_PB))\n",
      "\u001B[1;31mOSError\u001B[0m: SavedModel file does not exist at: C:\\Users\\saura\\AppData\\Local\\Temp\\tfhub_modules\\2bc8869ae42f586158bb5df0a65ce2103bcc940c\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "from natsort import natsorted\n",
    "import imageio\n",
    "model = hub.load(\"https://tfhub.dev/google/film/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "_UINT8_MAX_F = float(np.iinfo(np.uint8).max)\n",
    "def load_image(img_url: str):\n",
    "    \"\"\"Returns an image with shape [height, width, num_channels], with pixels in [0..1] range, and type np.float32.\"\"\"\n",
    "    image = imageio.imread(img_url)\n",
    "    image = image.astype(np.float32) / _UINT8_MAX_F\n",
    "    # image = np.expand_dims(image,2)\n",
    "    # image = np.dstack([image,image,image])\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-16T11:46:48.463814Z",
     "end_time": "2024-10-16T11:46:48.476826Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# ALL INPUTS HERE\n",
    "skips = [1]\n",
    "# Specify the folder path containing the images\n",
    "pth=r\"\\\\10.99.68.178\\Saurabh\\manuscript_figs\\data\\EM_seg\\authentic - Copy\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-16T11:46:48.477826Z",
     "end_time": "2024-10-16T11:46:48.496844Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# image_files = [_ for _ in os.listdir(pth) if _.endswith(('tif','png','jpg'))]\n",
    "# image_files = natsorted(image_files)\n",
    "#\n",
    "# image1 = load_image(os.path.join(pth,image_files[0])) #4D image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-16T11:47:31.049021Z",
     "end_time": "2024-10-16T11:47:31.059033Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saura\\AppData\\Local\\Temp\\ipykernel_1240\\4254188497.py:4: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(img_url)\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all image file names in the folder\n",
    "image_files = [_ for _ in os.listdir(pth) if _.endswith(('tif','png','jpg'))]\n",
    "image_files = natsorted(image_files)\n",
    "# image_files\n",
    "\n",
    "for skip_num in skips:\n",
    "    # Specify the output folder for the generated middle images\n",
    "    output_folder = os.path.join(pth,f'skip_{skip_num}')\n",
    "    os.mkdir(output_folder)\n",
    "    os.listdir(pth)\n",
    "\n",
    "    times = np.linspace(0,1,skip_num+2)\n",
    "    times = times[1:-1]\n",
    "\n",
    "    loaded_images = image_files[::skip_num + 1]\n",
    "    impairs = zip(loaded_images[:-1], loaded_images[1:])\n",
    "    imtargets = [image_files[i+1:i + skip_num+1] for i in range(0, len(image_files), skip_num + 1)]\n",
    "\n",
    "    for impair,imtarget in zip(impairs,imtargets):\n",
    "        image1 = load_image(os.path.join(pth,impair[0]))\n",
    "        image2 = load_image(os.path.join(pth,impair[1]))\n",
    "        for idx,time in enumerate(times):\n",
    "            time1 = np.array([time], dtype=np.float32)\n",
    "            # Prepare the input for the interpolation\n",
    "            input_data = {\n",
    "                'time': np.array([time1], dtype=np.float32),\n",
    "                'x0': np.expand_dims(image1, axis=0),\n",
    "                'x1': np.expand_dims(image2, axis=0)\n",
    "            }\n",
    "              # Generate the interpolated mid-frame using the model\n",
    "            mid_frame = model(input_data)\n",
    "            generated_image = mid_frame['image'][0].numpy()\n",
    "            # Convert the image to the appropriate range and type\n",
    "            image_in_uint8_range = np.clip(generated_image * _UINT8_MAX_F, 0.0, _UINT8_MAX_F)\n",
    "            image_in_uint8 = (image_in_uint8_range + 0.5).astype(np.uint8)\n",
    "            # Generate the filename for the generated middle image (using the next image filename)\n",
    "            filename = os.path.splitext(imtarget[idx])[0] + '.tif'\n",
    "            #filename = imtarget[idx]\n",
    "            # Save the generated middle image in the output folder\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            imageio.imwrite(output_path, image_in_uint8, format='tif')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-16T11:47:32.355213Z",
     "end_time": "2024-10-16T12:10:11.743652Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-01T12:16:06.762944Z",
     "end_time": "2024-08-01T12:16:06.776951Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-01T12:16:06.777951Z",
     "end_time": "2024-08-01T12:16:06.794195Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Path to the folder containing the images\n",
    "folder_path = r\"\\\\10.99.68.178\\Saurabh\\visium_trial\\Xenium_brain\\test_3_26_24\"\n",
    "\n",
    "# Iterate over all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".png\"):\n",
    "        # Open the image\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        # Convert image to RGB mode (remove alpha channel)\n",
    "        img = img.convert(\"RGB\")\n",
    "\n",
    "        # Save the image (overwrite the original)\n",
    "        img.save(image_path)\n",
    "\n",
    "print(\"Alpha channels removed from all PNG images in the folder.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
